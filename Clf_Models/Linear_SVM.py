# -*- coding: utf-8 -*-
"""METCS777-termproject-linearSVM_optimized_video.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xNOBwtesmI9a0VZw0j1JprOVJCwMw54z
"""

!pip install pyspark

from google.colab import drive
drive.mount('/content/drive')

from pyspark.sql import SparkSession
from pyspark.sql.types import IntegerType, DoubleType
from pyspark.sql import functions as F
from pyspark.sql.functions import col, lower, regexp_replace, when, udf, length
from pyspark.ml import Pipeline
from pyspark.ml.feature import RegexTokenizer, CountVectorizer, IDF, StopWordsRemover, StringIndexer, HashingTF
from pyspark.ml.classification import LogisticRegression, NaiveBayes, LinearSVC
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
from textblob import TextBlob
from sklearn.metrics import classification_report

# Initialize Spark Session
spark = SparkSession.builder \
    .appName("Amazon Review Sentiment Analysis") \
    .config("spark.executor.memory", "4g") \
    .config("spark.driver.memory", "4g") \
    .config("spark.executor.cores", "2") \
    .getOrCreate()

# VideoGameProcessed 9.03 GB
# Load all JSON data from the directory
df = spark.read.json('/content/drive/MyDrive/part-00000-b569cbab-0743-4611-8600-f2f072db3e69-c000.json')

df = df.dropDuplicates(['review_title'])

# Clean and preprocess text data
df = df.withColumn('text', lower(col('text')))
df = df.withColumn('text', regexp_replace('text', '[^a-zA-Z\\s]', ''))

df = df.select('rating', 'text')

df.filter(length(df['text']) == 0).count()
df = df.filter(length(df['text']) > 0)
df.filter(length(df['text']) == 0).count()

#%% Polarity score.

def polarity(text):
    return round(TextBlob(text).sentiment.polarity, 4)

def subjectivity(text):
    return round(TextBlob(text).sentiment.subjectivity, 4)

pola_udf = udf(polarity, DoubleType())
subj_udf = udf(subjectivity, DoubleType())

df = df.withColumn('polarity', pola_udf('text')) \
       .withColumn('subjectivity', subj_udf('text'))

df.show()

#%% Labeling.

df_by_rating = df.groupBy('rating').agg(
    F.mean('polarity').alias('polarity'),
    F.mean('subjectivity').alias('subjectivity')
)

rating_3_pola = df_by_rating.filter(df_by_rating.rating == 2.0) \
                            .select('polarity') \
                            .collect()[0]['polarity']

df = df.withColumn('sentiment_score',
                   when(col('rating') == 1, 0) \
                    .when(col('rating') == 2, 0) \
                    .when((col('rating') == 3) & (col('polarity') < rating_3_pola), 0)
                    .when((col('rating') == 3) & (col('polarity') >= rating_3_pola), 1) \
                    .when(col('rating') == 4, 1) \
                    .when(col('rating') == 5, 1))

df = df.withColumn('sentiment',
                   when(col('sentiment_score') == 0, 'Negative')
                   .when(col('sentiment_score') == 1, 'Positive'))

df.show()

#%% TF*IDF Vector.

tokenizer = RegexTokenizer(inputCol='text', outputCol='words', pattern='\W')
df_tokenized = tokenizer.transform(df)

hashingTF = HashingTF(inputCol='words', outputCol='raw_features')
df_TF = hashingTF.transform(df_tokenized)

idf = IDF(inputCol='raw_features', outputCol='features')
idf_model = idf.fit(df_TF)
df_idf = idf_model.transform(df_TF)

df_model = df_idf.select('features', 'sentiment_score') \
                 .withColumnRenamed('sentiment_score', 'label')

major_df = df_model.filter(col("label") == 1)
minor_df = df_model.filter(col("label") == 0)

# Count the number of instances in each class
major_df_count = major_df.count()
minor_df_count = minor_df.count()

# Calculate the fraction to which the minority class needs to be oversampled
oversample_ratio = major_df_count / minor_df_count

# Perform oversampling of the minority class
oversampled_minor_df = minor_df.sample(withReplacement=True, fraction=oversample_ratio, seed=33)

# Combine the majority class DataFrame and the oversampled minority class DataFrame
balanced_data = major_df.unionAll(oversampled_minor_df)
balanced_data.groupBy('label').count().show()

training_data, test_data = balanced_data.randomSplit([0.8, 0.2], seed=33)

svm = LinearSVC(featuresCol='features', labelCol='label', maxIter=5, regParam=0.01)
svm_model = svm.fit(training_data)

predictions = svm_model.transform(training_data)

evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction')

# accuracy = evaluator.evaluate(predictions, {evaluator.metricName: 'accuracy'})
precision = evaluator.evaluate(predictions, {evaluator.metricName: 'weightedPrecision'})
recall = evaluator.evaluate(predictions, {evaluator.metricName: 'weightedRecall'})
f1 = evaluator.evaluate(predictions, {evaluator.metricName: 'f1'})

# print("Accuracy: {:.4f}".format(accuracy))
print("Precision: {:.4f}".format(precision))
print("Recall: {:.4f}".format(recall))
print("F1 Score: {:.4f}".format(f1))

evaluator_auc = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction')
auc = evaluator_auc.evaluate(predictions, {evaluator.metricName: 'areaUnderROC'})
print("AUC: {:.4f}".format(auc))